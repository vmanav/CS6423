{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#/ Configuration/Setup Section \\"
      ],
      "metadata": {
        "id": "0NUYZFG0rFG1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wsAy1DKlSllu",
        "outputId": "d824e708-6dd1-42b2-f35e-5528767a71a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "\n",
            "All done!\n"
          ]
        }
      ],
      "source": [
        "############################################\n",
        "# 1. Imports & Setup\n",
        "############################################\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "from torchvision.models.resnet import Bottleneck\n",
        "import time\n",
        "import gc\n",
        "from copy import deepcopy\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "\n",
        "############################################\n",
        "# 2. Model Definitions\n",
        "############################################\n",
        "\n",
        "# RESNET101\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride,\n",
        "                               padding=1, bias=False)\n",
        "        self.bn1   = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1,\n",
        "                               padding=1, bias=False)\n",
        "        self.bn2   = nn.BatchNorm2d(planes)\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion * planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, self.expansion * planes, kernel_size=1,\n",
        "                          stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(self.expansion * planes)\n",
        "            )\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
        "                               stride=stride, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.conv3 = nn.Conv2d(planes, self.expansion *\n",
        "                               planes, kernel_size=1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion*planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, self.expansion*planes,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(self.expansion*planes)\n",
        "            )\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = F.relu(self.bn2(self.conv2(out)))\n",
        "        out = self.bn3(self.conv3(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, num_blocks, num_classes):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.in_planes = 64\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn1   = nn.BatchNorm2d(64)\n",
        "        self.layer1 = self._make_layer(block, 64,  num_blocks[0], stride=1)\n",
        "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
        "        self.linear = nn.Linear(512 * block.expansion, num_classes)\n",
        "    def _make_layer(self, block, planes, num_blocks, stride):\n",
        "        strides = [stride] + [1]*(num_blocks - 1)\n",
        "        layers = []\n",
        "        for st in strides:\n",
        "            layers.append(block(self.in_planes, planes, st))\n",
        "            self.in_planes = planes * block.expansion\n",
        "        return nn.Sequential(*layers)\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        out = F.avg_pool2d(out, 4)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear(out)\n",
        "        return out\n",
        "def ResNet18(num_classes): # Discard if not needed\n",
        "    return ResNet(BasicBlock, [2,2,2,2], num_classes)\n",
        "def ResNet101(num_classes):\n",
        "    return ResNet(Bottleneck, [3, 4, 23, 3], num_classes)\n",
        "\n",
        "# Pretrained weights loading paths from Google Drive:\n",
        "resnet18_weights_path = \"/content/drive/My Drive/Models/resnet18-cifar10.pth\" # Didn't know whether to keep get rid of Resnet18, remove if not needed\n",
        "resnet101_weights_path = \"/content/drive/My Drive/Models/resnet101-cifar100.pth\"\n",
        "\n",
        "def load_resnet_for_dataset(dataset_name): # Just a simple dataloader for either model/dataset\n",
        "    if dataset_name.lower() == 'cifar10':\n",
        "        model = ResNet18(num_classes=10).to(device)\n",
        "        model.load_state_dict(torch.load(resnet18_weights_path, map_location=device))\n",
        "    elif dataset_name.lower() == 'cifar100':\n",
        "        model = ResNet101(num_classes=100).to(device)\n",
        "        model.load_state_dict(torch.load(resnet101_weights_path, map_location=device))\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported dataset for ResNet model\")\n",
        "    return model\n",
        "\n",
        "# MOBILENETV2\n",
        "class MobileNetV2_Block(nn.Module):\n",
        "    def __init__(self, in_planes, out_planes, expansion, stride):\n",
        "        super(MobileNetV2_Block, self).__init__()\n",
        "        self.stride = stride\n",
        "        planes = expansion * in_planes\n",
        "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, stride=1, padding=0, bias=False)\n",
        "        self.bn1   = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1,\n",
        "                               groups=planes, bias=False)\n",
        "        self.bn2   = nn.BatchNorm2d(planes)\n",
        "        self.conv3 = nn.Conv2d(planes, out_planes, kernel_size=1, stride=1, padding=0, bias=False)\n",
        "        self.bn3   = nn.BatchNorm2d(out_planes)\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride == 1 and in_planes != out_planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=1, padding=0, bias=False),\n",
        "                nn.BatchNorm2d(out_planes)\n",
        "            )\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = F.relu(self.bn2(self.conv2(out)))\n",
        "        out = self.bn3(self.conv3(out))\n",
        "        if self.stride == 1:\n",
        "            out = out + self.shortcut(x)\n",
        "        return out\n",
        "\n",
        "class MobileNetV2(nn.Module):\n",
        "    cfg = [(1,  16, 1, 1),\n",
        "           (6,  24, 2, 1),  # For CIFAR, change stride from 2 to 1\n",
        "           (6,  32, 3, 2),\n",
        "           (6,  64, 4, 2),\n",
        "           (6,  96, 3, 1),\n",
        "           (6, 160, 3, 2),\n",
        "           (6, 320, 1, 1)]\n",
        "    def __init__(self, num_classes): # I Passed num_classes as an argument rather than assigning 100 or 10, check the next code cell for clarity\n",
        "        super(MobileNetV2, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn1   = nn.BatchNorm2d(32)\n",
        "        self.layers = self._make_layers(in_planes=32)\n",
        "        self.conv2 = nn.Conv2d(320, 1280, kernel_size=1, stride=1, padding=0, bias=False)\n",
        "        self.bn2   = nn.BatchNorm2d(1280)\n",
        "        self.linear = nn.Linear(1280, num_classes)\n",
        "    def _make_layers(self, in_planes):\n",
        "        layers = []\n",
        "        for expansion, out_planes, num_blocks, stride in self.cfg:\n",
        "            strides = [stride] + [1]*(num_blocks - 1)\n",
        "            for s in strides:\n",
        "                layers.append(MobileNetV2_Block(in_planes, out_planes, expansion, s))\n",
        "                in_planes = out_planes\n",
        "        return nn.Sequential(*layers)\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.layers(out)\n",
        "        out = F.relu(self.bn2(self.conv2(out)))\n",
        "        out = F.avg_pool2d(out, 4)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear(out)\n",
        "        return out\n",
        "\n",
        "# VGG16\n",
        "vgg_cfg = {\n",
        "    'VGG16': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M',\n",
        "              512, 512, 512, 'M', 512, 512, 512, 'M']\n",
        "}\n",
        "class VGG(nn.Module):\n",
        "    def __init__(self, num_classes, vgg_name=\"VGG16\"): # I Passed num_classes the same way with MobileNetv2 above\n",
        "        super(VGG, self).__init__()\n",
        "        self.features = self._make_layers(vgg_cfg[vgg_name])\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(512, 4096),\n",
        "            nn.ReLU(inplace=False),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(inplace=False),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(4096, num_classes)\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        out = self.features(x)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.classifier(out)\n",
        "        return out\n",
        "    def _make_layers(self, cfg):\n",
        "        layers = []\n",
        "        in_channels = 3\n",
        "        for x in cfg:\n",
        "            if x == 'M':\n",
        "                layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
        "            else:\n",
        "                layers += [nn.Conv2d(in_channels, x, kernel_size=3, padding=1),\n",
        "                           nn.BatchNorm2d(x),\n",
        "                           nn.ReLU(inplace=False)]\n",
        "                in_channels = x\n",
        "        layers += [nn.AvgPool2d(kernel_size=1, stride=1)]\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "\n",
        "\n",
        "############################################\n",
        "# 3. Mask-Based Pruning Engine\n",
        "############################################\n",
        "class pruning_engine_base:\n",
        "    def __init__(self, pruning_ratio, pruning_method):\n",
        "        self.pruning_ratio = 1 - pruning_ratio\n",
        "        self.pruning_method = pruning_method\n",
        "        self.mask_number = 0.0\n",
        "        self.device = device\n",
        "    def base_remove_filter_by_index(self, weight, remove_filter_idx,\n",
        "                                    bias=None, mean=None, var=None, linear=False):\n",
        "        with torch.no_grad():\n",
        "            if mean is not None:\n",
        "                for idx in remove_filter_idx:\n",
        "                    weight[idx.item()] = self.mask_number\n",
        "                    bias[idx.item()]   = self.mask_number\n",
        "                    mean[idx.item()]   = self.mask_number\n",
        "                    var[idx.item()]    = self.mask_number\n",
        "                return weight, bias, mean, var\n",
        "            elif bias is not None:\n",
        "                for idx in remove_filter_idx:\n",
        "                    weight[idx.item()] = self.mask_number\n",
        "                    bias[idx.item()]   = self.mask_number\n",
        "                return weight, bias\n",
        "            else:\n",
        "                for idx in remove_filter_idx:\n",
        "                    weight[idx.item()] = self.mask_number\n",
        "                return weight\n",
        "    def base_remove_kernel_by_index(self, weight, remove_filter_idx, linear=False):\n",
        "        with torch.no_grad():\n",
        "            for idx in remove_filter_idx:\n",
        "                weight[:, idx.item()] = self.mask_number\n",
        "        return weight\n",
        "\n",
        "class L1norm:\n",
        "    def L1norm_pruning(self, layer):\n",
        "        weight = layer.weight.data.clone()\n",
        "        if len(weight.shape) == 4:\n",
        "            importance = torch.sum(torch.abs(weight), dim=(1,2,3))\n",
        "        else:\n",
        "            importance = torch.sum(torch.abs(weight), dim=0)\n",
        "        _, sorted_idx = torch.sort(importance, dim=0, descending=True)\n",
        "        return sorted_idx\n",
        "\n",
        "\n",
        "class pruning_engine(pruning_engine_base):\n",
        "    def __init__(self, pruning_method, pruning_ratio=0.0, individual=False,\n",
        "                 conv_to_bn_map=None):\n",
        "        super().__init__(pruning_ratio, pruning_method)\n",
        "        self.conv_to_bn_map = conv_to_bn_map if conv_to_bn_map else {}\n",
        "        self.remove_filter_idx_history = {\"previous_layer\": None, \"current_layer\": None}\n",
        "        self.individual = individual\n",
        "        self.l1norm_pruning = L1norm()\n",
        "        self.pruning_criterion = self.l1norm_pruning.L1norm_pruning\n",
        "\n",
        "    def set_layer(self, layer, main_layer=False):\n",
        "        self.copy_layer = deepcopy(layer)\n",
        "        if main_layer:\n",
        "            if self.individual:\n",
        "                self.remove_filter_idx_history = {\"previous_layer\": None, \"current_layer\": None}\n",
        "            self.remove_filter_idx_history[\"previous_layer\"] = self.remove_filter_idx_history[\"current_layer\"]\n",
        "            self.remove_filter_idx_history[\"current_layer\"] = None\n",
        "            remove_filter_idx = self.pruning_criterion(self.copy_layer)\n",
        "            num_prune = int(len(remove_filter_idx) * self.pruning_ratio)\n",
        "            self.remove_filter_idx = remove_filter_idx[num_prune:]\n",
        "            if self.remove_filter_idx_history[\"previous_layer\"] is None:\n",
        "                self.remove_filter_idx_history[\"previous_layer\"] = self.remove_filter_idx\n",
        "            self.remove_filter_idx_history[\"current_layer\"] = self.remove_filter_idx\n",
        "        return True\n",
        "\n",
        "    def remove_conv_filter_kernel(self, conv_name=None, model=None):\n",
        "        if self.copy_layer.bias is not None:\n",
        "            w, b = self.base_remove_filter_by_index(\n",
        "                weight=self.copy_layer.weight.data,\n",
        "                remove_filter_idx=self.remove_filter_idx_history[\"current_layer\"],\n",
        "                bias=self.copy_layer.bias.data\n",
        "            )\n",
        "            self.copy_layer.weight.data = w\n",
        "            self.copy_layer.bias.data = b\n",
        "        else:\n",
        "            w = self.base_remove_filter_by_index(\n",
        "                weight=self.copy_layer.weight.data,\n",
        "                remove_filter_idx=self.remove_filter_idx_history[\"current_layer\"]\n",
        "            )\n",
        "            self.copy_layer.weight.data = w\n",
        "        if conv_name and model and (conv_name in self.conv_to_bn_map):\n",
        "            bn_name = self.conv_to_bn_map[conv_name]\n",
        "            bn_layer = get_module_by_name(model, bn_name)\n",
        "            self.remove_bn_layer(bn_layer, self.remove_filter_idx_history[\"current_layer\"])\n",
        "        return self.copy_layer\n",
        "\n",
        "    def remove_bn_layer(self, bn_layer, remove_filter_idx):\n",
        "        w, b, m, v = self.base_remove_filter_by_index(\n",
        "            weight=bn_layer.weight.data,\n",
        "            remove_filter_idx=remove_filter_idx,\n",
        "            bias=bn_layer.bias.data,\n",
        "            mean=bn_layer.running_mean.data,\n",
        "            var=bn_layer.running_var.data\n",
        "        )\n",
        "        bn_layer.weight.data = w\n",
        "        bn_layer.bias.data = b\n",
        "        bn_layer.running_mean.data = m\n",
        "        bn_layer.running_var.data = v\n",
        "\n",
        "\n",
        "\n",
        "############################################\n",
        "# 4. Training & Evaluation Functions\n",
        "############################################\n",
        "def train_model(model, dataloader, optimizer, criterion, num_epochs=1):\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        running_loss = 0.0\n",
        "        start_time = time.time()\n",
        "        for inputs, labels in dataloader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}] Loss: {running_loss/len(dataloader):.4f} Time: {time.time()-start_time:.2f}s\")\n",
        "    return model\n",
        "\n",
        "def evaluate_model(model, dataloader, topk=(1, 5)):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    top1_correct = 0\n",
        "    top5_correct = 0\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in dataloader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += labels.size(0)\n",
        "            correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "            # Top-k accuracy\n",
        "            _, pred = outputs.topk(max(topk), dim=1, largest=True, sorted=True)\n",
        "            top1_correct += pred[:, 0].eq(labels).sum().item()\n",
        "            top5_correct += torch.any(pred.eq(labels.view(-1, 1)), dim=1).sum().item()\n",
        "\n",
        "            # For F1/precision/recall\n",
        "            preds = outputs.argmax(dim=1)\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    acc = 100.0 * correct / total\n",
        "    top1_acc = 100.0 * top1_correct / total\n",
        "    top5_acc = 100.0 * top5_correct / total\n",
        "    precision = precision_score(all_labels, all_preds, average='macro', zero_division=0)\n",
        "    recall = recall_score(all_labels, all_preds, average='macro', zero_division=0)\n",
        "    f1 = f1_score(all_labels, all_preds, average='macro', zero_division=0)\n",
        "\n",
        "    print(f\"\\nEvaluation Metrics:\")\n",
        "    print(f\"Accuracy: {acc:.2f}%\")\n",
        "    print(f\"Top-1 Accuracy: {top1_acc:.2f}%\")\n",
        "    print(f\"Top-5 Accuracy: {top5_acc:.2f}%\")\n",
        "    print(f\"Precision (macro): {precision:.4f}\")\n",
        "    print(f\"Recall (macro):    {recall:.4f}\")\n",
        "    print(f\"F1 Score (macro):  {f1:.4f}\")\n",
        "\n",
        "    return acc, top1_acc, top5_acc, precision, recall, f1\n",
        "\n",
        "def get_module_by_name(model, access_string):\n",
        "    names = access_string.split('.')\n",
        "    module = model\n",
        "    for name in names:\n",
        "        module = getattr(module, name)\n",
        "    return module\n",
        "\n",
        "def set_module_by_name(model, access_string, new_module):\n",
        "    names = access_string.split('.')\n",
        "    module = model\n",
        "    for name in names[:-1]:\n",
        "        module = getattr(module, name)\n",
        "    setattr(module, names[-1], new_module)\n",
        "\n",
        "\n",
        "\n",
        "######################################################################################\n",
        "# 5. More Evaluation Metrics (Compression Ratio, Inference Speed)\n",
        "######################################################################################\n",
        "def count_nonzero_params(model):\n",
        "    total_params = sum(p.numel() for p in model.parameters())\n",
        "    nonzero_params = sum(torch.count_nonzero(p).item() for p in model.parameters())\n",
        "\n",
        "    if nonzero_params == 0:\n",
        "        compression_ratio = float('inf')  # Avoid division by zero\n",
        "    else:\n",
        "        compression_ratio = total_params / nonzero_params\n",
        "\n",
        "    sparsity = (1 - (nonzero_params / total_params)) * 100\n",
        "\n",
        "    print(f\"Total Parameters: {total_params}\")\n",
        "    print(f\"Nonzero Parameters: {nonzero_params}\")\n",
        "    print(f\"Compression Ratio: {compression_ratio:.3f}x\")\n",
        "    print(f\"Sparsity: {sparsity:.3f}%\")\n",
        "\n",
        "    return compression_ratio, sparsity\n",
        "\n",
        "def measure_inference_speed(model, testloader, device, num_batches=10):\n",
        "    model.eval()\n",
        "    total_time = 0.0\n",
        "    num_samples = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (inputs, _) in enumerate(testloader):\n",
        "            if i >= num_batches:\n",
        "                break\n",
        "\n",
        "            inputs = inputs.to(device)\n",
        "            start_time = time.time()\n",
        "            _ = model(inputs)\n",
        "            end_time = time.time()\n",
        "\n",
        "            batch_time = end_time - start_time\n",
        "            total_time += batch_time\n",
        "            num_samples += inputs.size(0)\n",
        "\n",
        "    if num_samples == 0:\n",
        "        print(\"Warning: No samples processed in measure_inference_speed. Returning default values.\")\n",
        "        return 0, 0\n",
        "\n",
        "    avg_time_per_sample = total_time / num_samples\n",
        "    avg_fps = num_samples / total_time\n",
        "\n",
        "    print(f\"Inference Speed: {avg_time_per_sample:.6f} sec/sample ({avg_fps:.2f} FPS)\")\n",
        "    return avg_time_per_sample, avg_fps\n",
        "\n",
        "\n",
        "####################################################################\n",
        "# 6. Example dataloader usage for ResNet, MobileNetV2, and VGG16\n",
        "####################################################################\n",
        "def get_dataloaders(dataset, batch_size=128):\n",
        "    if dataset == 'cifar10':\n",
        "        normalize = ((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))\n",
        "        trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True,\n",
        "                                                transform=transforms.Compose([\n",
        "                                                    transforms.RandomCrop(32, padding=4),\n",
        "                                                    transforms.RandomHorizontalFlip(),\n",
        "                                                    transforms.ToTensor(),\n",
        "                                                    transforms.Normalize(*normalize)\n",
        "                                                ]))\n",
        "        testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True,\n",
        "                                               transform=transforms.Compose([\n",
        "                                                   transforms.ToTensor(),\n",
        "                                                   transforms.Normalize(*normalize)\n",
        "                                               ]))\n",
        "        num_classes = 10\n",
        "    elif dataset == 'cifar100':\n",
        "        normalize = ((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761))\n",
        "        trainset = torchvision.datasets.CIFAR100(root='./data', train=True, download=True,\n",
        "                                                 transform=transforms.Compose([\n",
        "                                                     transforms.RandomCrop(32, padding=4),\n",
        "                                                     transforms.RandomHorizontalFlip(),\n",
        "                                                     transforms.ToTensor(),\n",
        "                                                     transforms.Normalize(*normalize)\n",
        "                                                 ]))\n",
        "        testset = torchvision.datasets.CIFAR100(root='./data', train=False, download=True,\n",
        "                                                transform=transforms.Compose([\n",
        "                                                    transforms.ToTensor(),\n",
        "                                                    transforms.Normalize(*normalize)\n",
        "                                                ]))\n",
        "        num_classes = 100\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported dataset name\")\n",
        "\n",
        "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "    testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=2)\n",
        "\n",
        "    return trainset, trainloader, testloader, num_classes\n",
        "\n",
        "print(\"\\nAll done!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading CIFAR10\n",
        "DATASET = \"cifar10\"\n",
        "trainset, trainloader, testloader, num_classes = get_dataloaders(DATASET)"
      ],
      "metadata": {
        "id": "osy_eHVrsmmk"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# / Model Tests \\"
      ],
      "metadata": {
        "id": "QH5eeB0Gq2fR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<hr>\n",
        "\n",
        "# CIFAR10 PRETRAINED MODELS SECTION\n",
        "### MobileNetV2"
      ],
      "metadata": {
        "id": "jwnCxOMGwMm-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## PRE-TRAINED TEST!!!!!\n",
        "print(\"\\n=== MobileNetV2 Example (CIFAR10) ===\")\n",
        "\n",
        "# 1) Define model architecture with correct num_classes\n",
        "mobilenet_model = MobileNetV2(num_classes=num_classes).to(device)\n",
        "\n",
        "# 2) Load pretrained weights from Google Drive\n",
        "model_path = \"/content/drive/MyDrive/Models/CIFAR10/Model@Mobilenetv2_ACC@95.82.pt\"\n",
        "checkpoint = torch.load(model_path, map_location=device)\n",
        "mobilenet_model.load_state_dict(checkpoint[\"state_dict\"])\n",
        "\n",
        "# 3) Optimizer + loss (optional fine-tuning)\n",
        "optimizer_mb = optim.Adam(mobilenet_model.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# 4) Baseline evaluation\n",
        "print(\"MobileNetV2 baseline evaluation:\")\n",
        "(mobileNet_acc_before, mobileNet_top1_acc_before, mobileNet_top5_acc_before,\n",
        " mobileNet_precision_before, mobileNet_recall_before, mobileNet_f1score_before\n",
        ") = evaluate_model(mobilenet_model, testloader)\n",
        "\n",
        "# 5) Build a list of all Conv2D layers, Pruning beyond first layer\n",
        "layer_store_mb = [m for m in mobilenet_model.modules() if isinstance(m, nn.Conv2d)]\n",
        "layers_to_prune_mb = [\n",
        "    name for name, module in mobilenet_model.named_modules()\n",
        "    if isinstance(module, nn.Conv2d) and 'shortcut' not in name and 'layers' not in name\n",
        "]\n",
        "conv_to_bn_map_mb = {}\n",
        "prev_conv = None\n",
        "for name, module in mobilenet_model.named_modules():\n",
        "    if isinstance(module, nn.Conv2d):\n",
        "        prev_conv = name\n",
        "    elif isinstance(module, nn.BatchNorm2d) and prev_conv:\n",
        "        conv_to_bn_map_mb[prev_conv] = name\n",
        "        prev_conv = None\n",
        "\n",
        "# 6) Check compression + speed BEFORE pruning\n",
        "print('\\nCompression Details BEFORE Pruning')\n",
        "mobileNet_compression_ratio_before, mobileNet_sparsity_before = count_nonzero_params(mobilenet_model)\n",
        "\n",
        "print(\"\\nMobileNetV2 inference speed BEFORE pruning:\")\n",
        "mobileNet_avg_time_per_sample_before, mobileNet_avg_fps_before = measure_inference_speed(mobilenet_model, testloader, device)\n",
        "print(f\"Inference Speed: {mobileNet_avg_time_per_sample_before:.6f} sec/sample ({mobileNet_avg_fps_before:.2f} FPS)\")\n",
        "\n",
        "\n",
        "# --------------------------------------------------------- #\n",
        "# ONE-SHOT PRUNING                                          #\n",
        "# --------------------------------------------------------- #\n",
        "print(\"\\n--- MobileNetV2 One-Shot Pruning (CIFAR10) ---\")\n",
        "\n",
        "prune_engine_mb = pruning_engine(\n",
        "    pruning_method=\"L1norm\",\n",
        "    pruning_ratio=0.2,           # 20% of filters are pruned\n",
        "    conv_to_bn_map=conv_to_bn_map_mb\n",
        ")\n",
        "\n",
        "for layer_name in layers_to_prune_mb:\n",
        "    print(f\"Pruning MobileNetV2 layer: {layer_name}\")\n",
        "    orig_layer = get_module_by_name(mobilenet_model, layer_name)\n",
        "    prune_engine_mb.set_layer(orig_layer, main_layer=True)\n",
        "    masked_layer = prune_engine_mb.remove_conv_filter_kernel(conv_name=layer_name, model=mobilenet_model)\n",
        "    set_module_by_name(mobilenet_model, layer_name, masked_layer)\n",
        "\n",
        "    # Adjust BatchNorm layer dynamically\n",
        "    if layer_name in conv_to_bn_map_mb:\n",
        "        bn_name = conv_to_bn_map_mb[layer_name]\n",
        "        bn_layer = get_module_by_name(mobilenet_model, bn_name)\n",
        "        prune_engine_mb.remove_bn_layer(bn_layer, prune_engine_mb.remove_filter_idx_history[\"current_layer\"])\n",
        "\n",
        "print(\"MobileNetV2 evaluation AFTER one-shot Pruning:\")\n",
        "(mobileNet_acc_oneshot, mobileNet_top1_acc_oneshot, mobileNet_top5_acc_oneshot,\n",
        " mobileNet_precision_oneshot, mobileNet_recall_oneshot, mobileNet_f1score_oneshot\n",
        ") = evaluate_model(mobilenet_model, testloader)\n",
        "\n",
        "# Checking stats after One-Shot\n",
        "print('\\nCompression Details AFTER One-Shot Pruning')\n",
        "mobileNet_compression_ratio_oneshot, mobileNet_sparsity_oneshot = count_nonzero_params(mobilenet_model)\n",
        "\n",
        "print(\"\\nMobileNetV2 inference speed AFTER One-Shot pruning:\")\n",
        "mobileNet_avg_time_per_sample_oneshot, mobileNet_avg_fps_oneshot = measure_inference_speed(mobilenet_model, testloader, device)\n",
        "print(f\"Inference Speed: {mobileNet_avg_time_per_sample_oneshot:.6f} sec/sample ({mobileNet_avg_fps_oneshot:.2f} FPS)\")\n",
        "\n",
        "\n",
        "# --------------------------------------------------------- #\n",
        "# ITERATIVE PRUNING                                         #\n",
        "# --------------------------------------------------------- #\n",
        "print(\"\\n--- MobileNetV2 Iterative Pruning (CIFAR10) ---\")\n",
        "num_iter = 2\n",
        "iter_mask_ratio = 0.1  # 10% pruned each iteration\n",
        "\n",
        "for it in range(num_iter):\n",
        "    print(f\"\\nIteration {it+1} for MobileNetV2\")\n",
        "\n",
        "    prune_engine_iter_mb = pruning_engine(\n",
        "        pruning_method=\"L1norm\",\n",
        "        pruning_ratio=iter_mask_ratio,\n",
        "        conv_to_bn_map=conv_to_bn_map_mb\n",
        "    )\n",
        "\n",
        "    for layer_name in layers_to_prune_mb:\n",
        "        print(f\"Pruning MobileNetV2 layer: {layer_name}\")\n",
        "        current_layer = get_module_by_name(mobilenet_model, layer_name)\n",
        "        prune_engine_iter_mb.set_layer(current_layer, main_layer=True)\n",
        "        masked_layer = prune_engine_iter_mb.remove_conv_filter_kernel(conv_name=layer_name, model=mobilenet_model)\n",
        "        set_module_by_name(mobilenet_model, layer_name, masked_layer)\n",
        "\n",
        "        # Also prune the Batchnorm, if optional\n",
        "        if layer_name in conv_to_bn_map_mb:\n",
        "            bn_name = conv_to_bn_map_mb[layer_name]\n",
        "            bn_layer = get_module_by_name(mobilenet_model, bn_name)\n",
        "            prune_engine_iter_mb.remove_bn_layer(bn_layer, prune_engine_iter_mb.remove_filter_idx_history[\"current_layer\"])\n",
        "\n",
        "    # Fine-tune\n",
        "    print(\"Fine-tuning MobileNetV2 after iteration...\")\n",
        "    train_model(mobilenet_model, trainloader, optimizer_mb, criterion, num_epochs=2)\n",
        "\n",
        "    # Evaluate\n",
        "    mobileNet_acc_iter, mobileNet_top1_acc_iter, mobileNet_top5_acc_iter, \\\n",
        "    mobileNet_precision_iter, mobileNet_recall_iter, mobileNet_f1score_iter = evaluate_model(mobilenet_model, testloader)\n",
        "\n",
        "\n",
        "# Final metrics after iterative pruning\n",
        "print('Compression Details AFTER Iterative Pruning')\n",
        "mobileNet_compression_ratio_iter, mobileNet_sparsity_iter = count_nonzero_params(mobilenet_model)\n",
        "\n",
        "print(\"\\nMobileNetV2 Model inference speed AFTER Iterative pruning:\")\n",
        "mobileNet_avg_time_per_sample_iter, mobileNet_avg_fps_iter = measure_inference_speed(mobilenet_model, testloader, device)\n",
        "print(f\"Inference Speed: {mobileNet_avg_time_per_sample_iter:.6f} sec/sample ({mobileNet_avg_fps_iter:.2f} FPS)\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WU3_JxBLq8pM",
        "outputId": "2987ec71-9577-4a43-a842-72e8da80710c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== MobileNetV2 Example (CIFAR10) ===\n",
            "MobileNetV2 baseline evaluation:\n",
            "\n",
            "Evaluation Metrics:\n",
            "Accuracy: 95.80%\n",
            "Top-1 Accuracy: 95.80%\n",
            "Top-5 Accuracy: 99.78%\n",
            "Precision (macro): 0.9580\n",
            "Recall (macro):    0.9580\n",
            "F1 Score (macro):  0.9579\n",
            "\n",
            "Compression Details BEFORE Pruning\n",
            "Total Parameters: 2296922\n",
            "Nonzero Parameters: 2296922\n",
            "Compression Ratio: 1.000x\n",
            "Sparsity: 0.000%\n",
            "\n",
            "MobileNetV2 inference speed BEFORE pruning:\n",
            "Inference Speed: 0.000318 sec/sample (3142.96 FPS)\n",
            "Inference Speed: 0.000318 sec/sample (3142.96 FPS)\n",
            "\n",
            "--- MobileNetV2 One-Shot Pruning (CIFAR10) ---\n",
            "Pruning MobileNetV2 layer: conv1\n",
            "Pruning MobileNetV2 layer: conv2\n",
            "MobileNetV2 evaluation AFTER one-shot Pruning:\n",
            "\n",
            "Evaluation Metrics:\n",
            "Accuracy: 95.50%\n",
            "Top-1 Accuracy: 95.50%\n",
            "Top-5 Accuracy: 99.80%\n",
            "Precision (macro): 0.9550\n",
            "Recall (macro):    0.9550\n",
            "F1 Score (macro):  0.9549\n",
            "\n",
            "Compression Details AFTER One-Shot Pruning\n",
            "Total Parameters: 2296922\n",
            "Nonzero Parameters: 2214287\n",
            "Compression Ratio: 1.037x\n",
            "Sparsity: 3.598%\n",
            "\n",
            "MobileNetV2 inference speed AFTER One-Shot pruning:\n",
            "Inference Speed: 0.000217 sec/sample (4597.82 FPS)\n",
            "Inference Speed: 0.000217 sec/sample (4597.82 FPS)\n",
            "\n",
            "--- MobileNetV2 Iterative Pruning (CIFAR10) ---\n",
            "\n",
            "Iteration 1 for MobileNetV2\n",
            "Pruning MobileNetV2 layer: conv1\n",
            "Pruning MobileNetV2 layer: conv2\n",
            "Fine-tuning MobileNetV2 after iteration...\n",
            "Epoch [1/2] Loss: 0.4027 Time: 46.47s\n",
            "Epoch [2/2] Loss: 0.3228 Time: 47.27s\n",
            "\n",
            "Evaluation Metrics:\n",
            "Accuracy: 86.55%\n",
            "Top-1 Accuracy: 86.55%\n",
            "Top-5 Accuracy: 99.51%\n",
            "Precision (macro): 0.8707\n",
            "Recall (macro):    0.8655\n",
            "F1 Score (macro):  0.8644\n",
            "\n",
            "Iteration 2 for MobileNetV2\n",
            "Pruning MobileNetV2 layer: conv1\n",
            "Pruning MobileNetV2 layer: conv2\n",
            "Fine-tuning MobileNetV2 after iteration...\n",
            "Epoch [1/2] Loss: 0.2953 Time: 47.75s\n",
            "Epoch [2/2] Loss: 0.2654 Time: 48.10s\n",
            "\n",
            "Evaluation Metrics:\n",
            "Accuracy: 90.07%\n",
            "Top-1 Accuracy: 90.07%\n",
            "Top-5 Accuracy: 99.74%\n",
            "Precision (macro): 0.9043\n",
            "Recall (macro):    0.9007\n",
            "F1 Score (macro):  0.9009\n",
            "Compression Details AFTER Iterative Pruning\n",
            "Total Parameters: 2296922\n",
            "Nonzero Parameters: 2214287\n",
            "Compression Ratio: 1.037x\n",
            "Sparsity: 3.598%\n",
            "\n",
            "MobileNetV2 Model inference speed AFTER Iterative pruning:\n",
            "Inference Speed: 0.000193 sec/sample (5191.17 FPS)\n",
            "Inference Speed: 0.000193 sec/sample (5191.17 FPS)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### VGG16"
      ],
      "metadata": {
        "id": "xSO4fXavwZPE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## PRE-TRAINED TEST!!!!\n",
        "print(\"\\n=== VGG16 Example (CIFAR10) ===\")\n",
        "\n",
        "# 1) Define VGG16 with correct num_classes\n",
        "vgg_model = VGG(num_classes=num_classes, vgg_name=\"VGG16\").to(device)\n",
        "\n",
        "# 2) Load pretrained weights\n",
        "model_path = \"/content/drive/MyDrive/Models/CIFAR10/Model@VGG16_ACC@95.26.pt\"\n",
        "checkpoint = torch.load(model_path, map_location=device)\n",
        "vgg_model.load_state_dict(checkpoint[\"state_dict\"])\n",
        "\n",
        "# 3) Set model to evaluation mode\n",
        "vgg_model.eval()\n",
        "\n",
        "# 4) Optimizer\n",
        "optimizer_vgg = optim.Adam(vgg_model.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# 5) Baseline evaluation\n",
        "print(\"VGG16 baseline evaluation:\")\n",
        "vgg_acc_before, vgg_top1_acc_before, vgg_top5_acc_before, vgg_precision_before, vgg_recall_before, vgg_f1score_before = evaluate_model(vgg_model, testloader)\n",
        "\n",
        "# Build a list of all Conv2D layers, Pruning beyond first layer\n",
        "layer_store_vgg = [m for m in vgg_model.modules() if isinstance(m, nn.Conv2d)]\n",
        "layers_to_prune_vgg = [\n",
        "    name for name, module in vgg_model.named_modules()\n",
        "    if isinstance(module, nn.Conv2d)\n",
        "]\n",
        "\n",
        "conv_to_bn_map_vgg = {}\n",
        "prev_conv = None\n",
        "for name, module in vgg_model.named_modules():\n",
        "    if isinstance(module, nn.Conv2d):\n",
        "        prev_conv = name\n",
        "    elif isinstance(module, nn.BatchNorm2d) and prev_conv:\n",
        "        conv_to_bn_map_vgg[prev_conv] = name\n",
        "        prev_conv = None\n",
        "\n",
        "# --- Before pruning stats ---\n",
        "print(f'\\nCompression Details BEFORE Pruning')\n",
        "vgg_compression_ratio_before, vgg_sparsity_before = count_nonzero_params(vgg_model)\n",
        "\n",
        "print(\"\\nVGG16 inference speed BEFORE pruning:\")\n",
        "vgg_avg_time_per_sample_before, vgg_avg_fps_before = measure_inference_speed(vgg_model, testloader, device)\n",
        "print(f\"Inference Speed: {vgg_avg_time_per_sample_before:.6f} sec/sample ({vgg_avg_fps_before:.2f} FPS)\")\n",
        "\n",
        "# --------------------------------------------------------- #\n",
        "# ONE-SHOT PRUNING                                          #\n",
        "# --------------------------------------------------------- #\n",
        "print(\"\\n--- VGG16 One-Shot Pruning (CIFAR10) ---\")\n",
        "\n",
        "prune_engine_vgg = pruning_engine(\n",
        "    pruning_method=\"L1norm\",\n",
        "    pruning_ratio=0.2,  # 20% pruned\n",
        "    conv_to_bn_map=conv_to_bn_map_vgg\n",
        ")\n",
        "\n",
        "for layer_name in layers_to_prune_vgg:\n",
        "    print(f\"Pruning VGG16 layer: {layer_name}\")\n",
        "    orig_layer = get_module_by_name(vgg_model, layer_name)\n",
        "    prune_engine_vgg.set_layer(orig_layer, main_layer=True)\n",
        "    masked_layer = prune_engine_vgg.remove_conv_filter_kernel(conv_name=layer_name, model=vgg_model)\n",
        "    set_module_by_name(vgg_model, layer_name, masked_layer)\n",
        "\n",
        "print(\"VGG16 evaluation after one-shot Pruning:\")\n",
        "vgg_acc_oneshot, vgg_top1_acc_oneshot, vgg_top5_acc_oneshot, vgg_prec_oneshot, vgg_rec_oneshot, vgg_f1_oneshot = evaluate_model(vgg_model, testloader)\n",
        "\n",
        "# After one-shot stats\n",
        "print(f'\\nCompression Details AFTER One-Shot Pruning')\n",
        "vgg_compression_ratio_oneshot, vgg_sparsity_oneshot = count_nonzero_params(vgg_model)\n",
        "\n",
        "print(\"\\nVGG16 inference speed AFTER One-Shot pruning:\")\n",
        "vgg_avg_time_per_sample_oneshot, vgg_avg_fps_oneshot = measure_inference_speed(vgg_model, testloader, device)\n",
        "print(f\"Inference Speed: {vgg_avg_time_per_sample_oneshot:.6f} sec/sample ({vgg_avg_fps_oneshot:.2f} FPS)\")\n",
        "\n",
        "\n",
        "# --------------------------------------------------------- #\n",
        "# ITERATIVE PRUNING                                         #\n",
        "# --------------------------------------------------------- #\n",
        "print(\"\\n--- VGG16 Iterative Pruning (CIFAR10) ---\")\n",
        "num_iter = 2\n",
        "iter_mask_ratio = 0.1  # 10% each iteration\n",
        "\n",
        "for it in range(num_iter):\n",
        "    print(f\"\\nIteration {it+1} for VGG16\")\n",
        "\n",
        "    prune_engine_iter_vgg = pruning_engine(\n",
        "        pruning_method=\"L1norm\",\n",
        "        pruning_ratio=iter_mask_ratio,\n",
        "        conv_to_bn_map=conv_to_bn_map_vgg\n",
        "    )\n",
        "\n",
        "    for layer_name in layers_to_prune_vgg:\n",
        "        print(f\"Pruning VGG16 layer: {layer_name}\")\n",
        "        current_layer = get_module_by_name(vgg_model, layer_name)\n",
        "        prune_engine_iter_vgg.set_layer(current_layer, main_layer=True)\n",
        "        masked_layer = prune_engine_iter_vgg.remove_conv_filter_kernel(conv_name=layer_name, model=vgg_model)\n",
        "        set_module_by_name(vgg_model, layer_name, masked_layer)\n",
        "\n",
        "    print(\"Fine-tuning VGG16 after iteration...\")\n",
        "    vgg_model = train_model(vgg_model, trainloader, optimizer_vgg, criterion, num_epochs=2)\n",
        "    evaluate_model(vgg_model, testloader)\n",
        "\n",
        "# Final stats after iterative pruning\n",
        "print('Compression Details After Iterative Pruning')\n",
        "vgg_compression_ratio_iter, vgg_sparsity_iter = count_nonzero_params(vgg_model)\n",
        "\n",
        "print(\"\\nVGG16 inference speed AFTER Iterative pruning:\")\n",
        "vgg_avg_time_per_sample_iter, vgg_avg_fps_iter = measure_inference_speed(vgg_model, testloader, device)\n",
        "print(f\"Inference Speed: {vgg_avg_time_per_sample_iter:.6f} sec/sample ({vgg_avg_fps_iter:.2f} FPS)\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lfGzrvOcwZ3U",
        "outputId": "c1b67dd6-b5e3-40bd-8975-f28bc55f0f44"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== VGG16 Example (CIFAR10) ===\n",
            "VGG16 baseline evaluation:\n",
            "\n",
            "Evaluation Metrics:\n",
            "Accuracy: 95.43%\n",
            "Top-1 Accuracy: 95.43%\n",
            "Top-5 Accuracy: 99.85%\n",
            "Precision (macro): 0.9544\n",
            "Recall (macro):    0.9543\n",
            "F1 Score (macro):  0.9542\n",
            "\n",
            "Compression Details BEFORE Pruning\n",
            "Total Parameters: 33646666\n",
            "Nonzero Parameters: 33646666\n",
            "Compression Ratio: 1.000x\n",
            "Sparsity: 0.000%\n",
            "\n",
            "VGG16 inference speed BEFORE pruning:\n",
            "Inference Speed: 0.000061 sec/sample (16442.64 FPS)\n",
            "Inference Speed: 0.000061 sec/sample (16442.64 FPS)\n",
            "\n",
            "--- VGG16 One-Shot Pruning (CIFAR10) ---\n",
            "Pruning VGG16 layer: features.0\n",
            "Pruning VGG16 layer: features.3\n",
            "Pruning VGG16 layer: features.7\n",
            "Pruning VGG16 layer: features.10\n",
            "Pruning VGG16 layer: features.14\n",
            "Pruning VGG16 layer: features.17\n",
            "Pruning VGG16 layer: features.20\n",
            "Pruning VGG16 layer: features.24\n",
            "Pruning VGG16 layer: features.27\n",
            "Pruning VGG16 layer: features.30\n",
            "Pruning VGG16 layer: features.34\n",
            "Pruning VGG16 layer: features.37\n",
            "Pruning VGG16 layer: features.40\n",
            "VGG16 evaluation after one-shot Pruning:\n",
            "\n",
            "Evaluation Metrics:\n",
            "Accuracy: 60.84%\n",
            "Top-1 Accuracy: 60.84%\n",
            "Top-5 Accuracy: 89.08%\n",
            "Precision (macro): 0.7742\n",
            "Recall (macro):    0.6084\n",
            "F1 Score (macro):  0.6032\n",
            "\n",
            "Compression Details AFTER One-Shot Pruning\n",
            "Total Parameters: 33646666\n",
            "Nonzero Parameters: 30681391\n",
            "Compression Ratio: 1.097x\n",
            "Sparsity: 8.813%\n",
            "\n",
            "VGG16 inference speed AFTER One-Shot pruning:\n",
            "Inference Speed: 0.000051 sec/sample (19462.41 FPS)\n",
            "Inference Speed: 0.000051 sec/sample (19462.41 FPS)\n",
            "\n",
            "--- VGG16 Iterative Pruning (CIFAR10) ---\n",
            "\n",
            "Iteration 1 for VGG16\n",
            "Pruning VGG16 layer: features.0\n",
            "Pruning VGG16 layer: features.3\n",
            "Pruning VGG16 layer: features.7\n",
            "Pruning VGG16 layer: features.10\n",
            "Pruning VGG16 layer: features.14\n",
            "Pruning VGG16 layer: features.17\n",
            "Pruning VGG16 layer: features.20\n",
            "Pruning VGG16 layer: features.24\n",
            "Pruning VGG16 layer: features.27\n",
            "Pruning VGG16 layer: features.30\n",
            "Pruning VGG16 layer: features.34\n",
            "Pruning VGG16 layer: features.37\n",
            "Pruning VGG16 layer: features.40\n",
            "Fine-tuning VGG16 after iteration...\n",
            "Epoch [1/2] Loss: 0.1262 Time: 27.37s\n",
            "Epoch [2/2] Loss: 0.0976 Time: 27.24s\n",
            "\n",
            "Evaluation Metrics:\n",
            "Accuracy: 92.57%\n",
            "Top-1 Accuracy: 92.57%\n",
            "Top-5 Accuracy: 99.57%\n",
            "Precision (macro): 0.9268\n",
            "Recall (macro):    0.9257\n",
            "F1 Score (macro):  0.9255\n",
            "\n",
            "Iteration 2 for VGG16\n",
            "Pruning VGG16 layer: features.0\n",
            "Pruning VGG16 layer: features.3\n",
            "Pruning VGG16 layer: features.7\n",
            "Pruning VGG16 layer: features.10\n",
            "Pruning VGG16 layer: features.14\n",
            "Pruning VGG16 layer: features.17\n",
            "Pruning VGG16 layer: features.20\n",
            "Pruning VGG16 layer: features.24\n",
            "Pruning VGG16 layer: features.27\n",
            "Pruning VGG16 layer: features.30\n",
            "Pruning VGG16 layer: features.34\n",
            "Pruning VGG16 layer: features.37\n",
            "Pruning VGG16 layer: features.40\n",
            "Fine-tuning VGG16 after iteration...\n",
            "Epoch [1/2] Loss: 0.0855 Time: 27.50s\n",
            "Epoch [2/2] Loss: 0.0832 Time: 27.38s\n",
            "\n",
            "Evaluation Metrics:\n",
            "Accuracy: 92.73%\n",
            "Top-1 Accuracy: 92.73%\n",
            "Top-5 Accuracy: 99.56%\n",
            "Precision (macro): 0.9270\n",
            "Recall (macro):    0.9273\n",
            "F1 Score (macro):  0.9269\n",
            "Compression Details After Iterative Pruning\n",
            "Total Parameters: 33646666\n",
            "Nonzero Parameters: 30681391\n",
            "Compression Ratio: 1.097x\n",
            "Sparsity: 8.813%\n",
            "\n",
            "VGG16 inference speed AFTER Iterative pruning:\n",
            "Inference Speed: 0.000057 sec/sample (17642.77 FPS)\n",
            "Inference Speed: 0.000057 sec/sample (17642.77 FPS)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<hr>\n",
        "\n",
        "# CIFAR100 PRETRAINED MODELS SECTION\n"
      ],
      "metadata": {
        "id": "y_rPYhiu4LzV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading CIFAR100\n",
        "DATASET = \"cifar100\"\n",
        "trainset, trainloader, testloader, num_classes = get_dataloaders(DATASET)"
      ],
      "metadata": {
        "id": "EuWn4I-2yAAb"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Resnet101"
      ],
      "metadata": {
        "id": "pE4jsnvX4gme"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n=== ResNet101 Example (CIFAR-100) ===\")\n",
        "\n",
        "# 1) Define model\n",
        "resnet_model = ResNet101(num_classes=num_classes).to(device)\n",
        "\n",
        "# 2) Load pretrained weights\n",
        "model_path = \"/content/drive/My Drive/Models/CIFAR100/Model@ResNet101_ACC@83.41.pt\"\n",
        "checkpoint = torch.load(model_path, map_location=device)\n",
        "resnet_model.load_state_dict(checkpoint)\n",
        "resnet_model.eval()\n",
        "\n",
        "# 3) Optimizer + Loss\n",
        "optimizer_res = optim.Adam(resnet_model.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# === Baseline Evaluation === #\n",
        "print(\"ResNet101 baseline evaluation:\")\n",
        "res_acc_before, res_top1_before, res_top5_before, res_precision_before, res_recall_before, res_f1_before = evaluate_model(resnet_model, testloader)\n",
        "\n",
        "print(\"\\nCompression Details BEFORE Pruning:\")\n",
        "res_compression_before, res_sparsity_before = count_nonzero_params(resnet_model)\n",
        "\n",
        "print(\"\\nResNet101 inference speed BEFORE pruning:\")\n",
        "res_time_before, res_fps_before = measure_inference_speed(resnet_model, testloader, device)\n",
        "print(f\"Inference Speed: {res_time_before:.6f} sec/sample ({res_fps_before:.2f} FPS)\")\n",
        "\n",
        "# 4) Setup for Pruning\n",
        "layers_to_prune_res = [\n",
        "    name for name, module in resnet_model.named_modules()\n",
        "    if isinstance(module, nn.Conv2d) and 'shortcut' not in name\n",
        "]\n",
        "\n",
        "conv_to_bn_map_res = {}\n",
        "prev_conv = None\n",
        "for name, module in resnet_model.named_modules():\n",
        "    if isinstance(module, nn.Conv2d):\n",
        "        prev_conv = name\n",
        "    elif isinstance(module, nn.BatchNorm2d) and prev_conv:\n",
        "        conv_to_bn_map_res[prev_conv] = name\n",
        "        prev_conv = None\n",
        "\n",
        "# --------------------------------------------------------- #\n",
        "# ONE-SHOT PRUNING                                          #\n",
        "# --------------------------------------------------------- #\n",
        "print(\"\\n--- ResNet101 One-Shot Pruning (CIFAR-100) ---\")\n",
        "prune_engine_res = pruning_engine(\n",
        "    pruning_method=\"L1norm\",\n",
        "    pruning_ratio=0.2,\n",
        "    conv_to_bn_map=conv_to_bn_map_res\n",
        ")\n",
        "\n",
        "for layer_name in layers_to_prune_res:\n",
        "    print(f\"Pruning layer: {layer_name}\")\n",
        "    orig_layer = get_module_by_name(resnet_model, layer_name)\n",
        "    prune_engine_res.set_layer(orig_layer, main_layer=True)\n",
        "    masked_layer = prune_engine_res.remove_conv_filter_kernel(conv_name=layer_name, model=resnet_model)\n",
        "    set_module_by_name(resnet_model, layer_name, masked_layer)\n",
        "\n",
        "print(\"ResNet101 evaluation AFTER One-Shot Pruning:\")\n",
        "res_acc_oneshot, res_top1_oneshot, res_top5_oneshot, res_precision_oneshot, res_recall_oneshot, res_f1_oneshot = evaluate_model(resnet_model, testloader)\n",
        "\n",
        "print(\"\\nCompression Details AFTER One-Shot Pruning:\")\n",
        "res_compression_oneshot, res_sparsity_oneshot = count_nonzero_params(resnet_model)\n",
        "\n",
        "print(\"\\nResNet101 inference speed AFTER One-Shot Pruning:\")\n",
        "res_time_oneshot, res_fps_oneshot = measure_inference_speed(resnet_model, testloader, device)\n",
        "print(f\"Inference Speed: {res_time_oneshot:.6f} sec/sample ({res_fps_oneshot:.2f} FPS)\")\n",
        "\n",
        "# --------------------------------------------------------- #\n",
        "# ITERATIVE PRUNING                                         #\n",
        "# --------------------------------------------------------- #\n",
        "print(\"\\n--- ResNet101 Iterative Pruning (CIFAR-100) ---\")\n",
        "num_iter = 2\n",
        "iter_mask_ratio = 0.1\n",
        "\n",
        "for it in range(num_iter):\n",
        "    print(f\"\\nIteration {it + 1}\")\n",
        "\n",
        "    prune_engine_iter = pruning_engine(\n",
        "        pruning_method=\"L1norm\",\n",
        "        pruning_ratio=iter_mask_ratio,\n",
        "        conv_to_bn_map=conv_to_bn_map_res\n",
        "    )\n",
        "\n",
        "    for layer_name in layers_to_prune_res:\n",
        "        print(f\"Pruning layer: {layer_name}\")\n",
        "        current_layer = get_module_by_name(resnet_model, layer_name)\n",
        "        prune_engine_iter.set_layer(current_layer, main_layer=True)\n",
        "        masked_layer = prune_engine_iter.remove_conv_filter_kernel(conv_name=layer_name, model=resnet_model)\n",
        "        set_module_by_name(resnet_model, layer_name, masked_layer)\n",
        "\n",
        "    print(\"Fine-tuning ResNet101 AFTER pruning iteration...\")\n",
        "    resnet_model = train_model(resnet_model, trainloader, optimizer_res, criterion, num_epochs=2)\n",
        "    res_acc_iter, res_top1_iter, res_top5_iter, res_precision_iter, res_recall_iter, res_f1_iter = evaluate_model(resnet_model, testloader)\n",
        "\n",
        "# Final compression + speed\n",
        "print(\"\\nCompression Details AFTER Iterative Pruning:\")\n",
        "res_compression_iter, res_sparsity_iter = count_nonzero_params(resnet_model)\n",
        "\n",
        "print(\"\\nResNet101 inference speed AFTER Iterative Pruning:\")\n",
        "res_time_iter, res_fps_iter = measure_inference_speed(resnet_model, testloader, device)\n",
        "print(f\"Inference Speed: {res_time_iter:.6f} sec/sample ({res_fps_iter:.2f} FPS)\")\n",
        "\n",
        "print(\"\\nAll done!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UYu_qjDryG-0",
        "outputId": "20703999-a580-4aa3-d2f2-0e6edd01b971"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== ResNet101 Example (CIFAR-100) ===\n",
            "ResNet101 baseline evaluation:\n",
            "\n",
            "Evaluation Metrics:\n",
            "Accuracy: 83.38%\n",
            "Top-1 Accuracy: 83.38%\n",
            "Top-5 Accuracy: 96.20%\n",
            "Precision (macro): 0.8353\n",
            "Recall (macro):    0.8338\n",
            "F1 Score (macro):  0.8336\n",
            "\n",
            "Compression Details BEFORE Pruning:\n",
            "Total Parameters: 42697380\n",
            "Nonzero Parameters: 42697380\n",
            "Compression Ratio: 1.000x\n",
            "Sparsity: 0.000%\n",
            "\n",
            "ResNet101 inference speed BEFORE pruning:\n",
            "Inference Speed: 0.000190 sec/sample (5261.21 FPS)\n",
            "Inference Speed: 0.000190 sec/sample (5261.21 FPS)\n",
            "\n",
            "--- ResNet101 One-Shot Pruning (CIFAR-100) ---\n",
            "Pruning layer: conv1\n",
            "Pruning layer: layer1.0.conv1\n",
            "Pruning layer: layer1.0.conv2\n",
            "Pruning layer: layer1.0.conv3\n",
            "Pruning layer: layer1.1.conv1\n",
            "Pruning layer: layer1.1.conv2\n",
            "Pruning layer: layer1.1.conv3\n",
            "Pruning layer: layer1.2.conv1\n",
            "Pruning layer: layer1.2.conv2\n",
            "Pruning layer: layer1.2.conv3\n",
            "Pruning layer: layer2.0.conv1\n",
            "Pruning layer: layer2.0.conv2\n",
            "Pruning layer: layer2.0.conv3\n",
            "Pruning layer: layer2.1.conv1\n",
            "Pruning layer: layer2.1.conv2\n",
            "Pruning layer: layer2.1.conv3\n",
            "Pruning layer: layer2.2.conv1\n",
            "Pruning layer: layer2.2.conv2\n",
            "Pruning layer: layer2.2.conv3\n",
            "Pruning layer: layer2.3.conv1\n",
            "Pruning layer: layer2.3.conv2\n",
            "Pruning layer: layer2.3.conv3\n",
            "Pruning layer: layer3.0.conv1\n",
            "Pruning layer: layer3.0.conv2\n",
            "Pruning layer: layer3.0.conv3\n",
            "Pruning layer: layer3.1.conv1\n",
            "Pruning layer: layer3.1.conv2\n",
            "Pruning layer: layer3.1.conv3\n",
            "Pruning layer: layer3.2.conv1\n",
            "Pruning layer: layer3.2.conv2\n",
            "Pruning layer: layer3.2.conv3\n",
            "Pruning layer: layer3.3.conv1\n",
            "Pruning layer: layer3.3.conv2\n",
            "Pruning layer: layer3.3.conv3\n",
            "Pruning layer: layer3.4.conv1\n",
            "Pruning layer: layer3.4.conv2\n",
            "Pruning layer: layer3.4.conv3\n",
            "Pruning layer: layer3.5.conv1\n",
            "Pruning layer: layer3.5.conv2\n",
            "Pruning layer: layer3.5.conv3\n",
            "Pruning layer: layer3.6.conv1\n",
            "Pruning layer: layer3.6.conv2\n",
            "Pruning layer: layer3.6.conv3\n",
            "Pruning layer: layer3.7.conv1\n",
            "Pruning layer: layer3.7.conv2\n",
            "Pruning layer: layer3.7.conv3\n",
            "Pruning layer: layer3.8.conv1\n",
            "Pruning layer: layer3.8.conv2\n",
            "Pruning layer: layer3.8.conv3\n",
            "Pruning layer: layer3.9.conv1\n",
            "Pruning layer: layer3.9.conv2\n",
            "Pruning layer: layer3.9.conv3\n",
            "Pruning layer: layer3.10.conv1\n",
            "Pruning layer: layer3.10.conv2\n",
            "Pruning layer: layer3.10.conv3\n",
            "Pruning layer: layer3.11.conv1\n",
            "Pruning layer: layer3.11.conv2\n",
            "Pruning layer: layer3.11.conv3\n",
            "Pruning layer: layer3.12.conv1\n",
            "Pruning layer: layer3.12.conv2\n",
            "Pruning layer: layer3.12.conv3\n",
            "Pruning layer: layer3.13.conv1\n",
            "Pruning layer: layer3.13.conv2\n",
            "Pruning layer: layer3.13.conv3\n",
            "Pruning layer: layer3.14.conv1\n",
            "Pruning layer: layer3.14.conv2\n",
            "Pruning layer: layer3.14.conv3\n",
            "Pruning layer: layer3.15.conv1\n",
            "Pruning layer: layer3.15.conv2\n",
            "Pruning layer: layer3.15.conv3\n",
            "Pruning layer: layer3.16.conv1\n",
            "Pruning layer: layer3.16.conv2\n",
            "Pruning layer: layer3.16.conv3\n",
            "Pruning layer: layer3.17.conv1\n",
            "Pruning layer: layer3.17.conv2\n",
            "Pruning layer: layer3.17.conv3\n",
            "Pruning layer: layer3.18.conv1\n",
            "Pruning layer: layer3.18.conv2\n",
            "Pruning layer: layer3.18.conv3\n",
            "Pruning layer: layer3.19.conv1\n",
            "Pruning layer: layer3.19.conv2\n",
            "Pruning layer: layer3.19.conv3\n",
            "Pruning layer: layer3.20.conv1\n",
            "Pruning layer: layer3.20.conv2\n",
            "Pruning layer: layer3.20.conv3\n",
            "Pruning layer: layer3.21.conv1\n",
            "Pruning layer: layer3.21.conv2\n",
            "Pruning layer: layer3.21.conv3\n",
            "Pruning layer: layer3.22.conv1\n",
            "Pruning layer: layer3.22.conv2\n",
            "Pruning layer: layer3.22.conv3\n",
            "Pruning layer: layer4.0.conv1\n",
            "Pruning layer: layer4.0.conv2\n",
            "Pruning layer: layer4.0.conv3\n",
            "Pruning layer: layer4.1.conv1\n",
            "Pruning layer: layer4.1.conv2\n",
            "Pruning layer: layer4.1.conv3\n",
            "Pruning layer: layer4.2.conv1\n",
            "Pruning layer: layer4.2.conv2\n",
            "Pruning layer: layer4.2.conv3\n",
            "ResNet101 evaluation AFTER One-Shot Pruning:\n",
            "\n",
            "Evaluation Metrics:\n",
            "Accuracy: 29.43%\n",
            "Top-1 Accuracy: 29.43%\n",
            "Top-5 Accuracy: 60.27%\n",
            "Precision (macro): 0.6627\n",
            "Recall (macro):    0.2943\n",
            "F1 Score (macro):  0.3443\n",
            "\n",
            "Compression Details AFTER One-Shot Pruning:\n",
            "Total Parameters: 42697380\n",
            "Nonzero Parameters: 34676617\n",
            "Compression Ratio: 1.231x\n",
            "Sparsity: 18.785%\n",
            "\n",
            "ResNet101 inference speed AFTER One-Shot Pruning:\n",
            "Inference Speed: 0.000186 sec/sample (5387.82 FPS)\n",
            "Inference Speed: 0.000186 sec/sample (5387.82 FPS)\n",
            "\n",
            "--- ResNet101 Iterative Pruning (CIFAR-100) ---\n",
            "\n",
            "Iteration 1\n",
            "Pruning layer: conv1\n",
            "Pruning layer: layer1.0.conv1\n",
            "Pruning layer: layer1.0.conv2\n",
            "Pruning layer: layer1.0.conv3\n",
            "Pruning layer: layer1.1.conv1\n",
            "Pruning layer: layer1.1.conv2\n",
            "Pruning layer: layer1.1.conv3\n",
            "Pruning layer: layer1.2.conv1\n",
            "Pruning layer: layer1.2.conv2\n",
            "Pruning layer: layer1.2.conv3\n",
            "Pruning layer: layer2.0.conv1\n",
            "Pruning layer: layer2.0.conv2\n",
            "Pruning layer: layer2.0.conv3\n",
            "Pruning layer: layer2.1.conv1\n",
            "Pruning layer: layer2.1.conv2\n",
            "Pruning layer: layer2.1.conv3\n",
            "Pruning layer: layer2.2.conv1\n",
            "Pruning layer: layer2.2.conv2\n",
            "Pruning layer: layer2.2.conv3\n",
            "Pruning layer: layer2.3.conv1\n",
            "Pruning layer: layer2.3.conv2\n",
            "Pruning layer: layer2.3.conv3\n",
            "Pruning layer: layer3.0.conv1\n",
            "Pruning layer: layer3.0.conv2\n",
            "Pruning layer: layer3.0.conv3\n",
            "Pruning layer: layer3.1.conv1\n",
            "Pruning layer: layer3.1.conv2\n",
            "Pruning layer: layer3.1.conv3\n",
            "Pruning layer: layer3.2.conv1\n",
            "Pruning layer: layer3.2.conv2\n",
            "Pruning layer: layer3.2.conv3\n",
            "Pruning layer: layer3.3.conv1\n",
            "Pruning layer: layer3.3.conv2\n",
            "Pruning layer: layer3.3.conv3\n",
            "Pruning layer: layer3.4.conv1\n",
            "Pruning layer: layer3.4.conv2\n",
            "Pruning layer: layer3.4.conv3\n",
            "Pruning layer: layer3.5.conv1\n",
            "Pruning layer: layer3.5.conv2\n",
            "Pruning layer: layer3.5.conv3\n",
            "Pruning layer: layer3.6.conv1\n",
            "Pruning layer: layer3.6.conv2\n",
            "Pruning layer: layer3.6.conv3\n",
            "Pruning layer: layer3.7.conv1\n",
            "Pruning layer: layer3.7.conv2\n",
            "Pruning layer: layer3.7.conv3\n",
            "Pruning layer: layer3.8.conv1\n",
            "Pruning layer: layer3.8.conv2\n",
            "Pruning layer: layer3.8.conv3\n",
            "Pruning layer: layer3.9.conv1\n",
            "Pruning layer: layer3.9.conv2\n",
            "Pruning layer: layer3.9.conv3\n",
            "Pruning layer: layer3.10.conv1\n",
            "Pruning layer: layer3.10.conv2\n",
            "Pruning layer: layer3.10.conv3\n",
            "Pruning layer: layer3.11.conv1\n",
            "Pruning layer: layer3.11.conv2\n",
            "Pruning layer: layer3.11.conv3\n",
            "Pruning layer: layer3.12.conv1\n",
            "Pruning layer: layer3.12.conv2\n",
            "Pruning layer: layer3.12.conv3\n",
            "Pruning layer: layer3.13.conv1\n",
            "Pruning layer: layer3.13.conv2\n",
            "Pruning layer: layer3.13.conv3\n",
            "Pruning layer: layer3.14.conv1\n",
            "Pruning layer: layer3.14.conv2\n",
            "Pruning layer: layer3.14.conv3\n",
            "Pruning layer: layer3.15.conv1\n",
            "Pruning layer: layer3.15.conv2\n",
            "Pruning layer: layer3.15.conv3\n",
            "Pruning layer: layer3.16.conv1\n",
            "Pruning layer: layer3.16.conv2\n",
            "Pruning layer: layer3.16.conv3\n",
            "Pruning layer: layer3.17.conv1\n",
            "Pruning layer: layer3.17.conv2\n",
            "Pruning layer: layer3.17.conv3\n",
            "Pruning layer: layer3.18.conv1\n",
            "Pruning layer: layer3.18.conv2\n",
            "Pruning layer: layer3.18.conv3\n",
            "Pruning layer: layer3.19.conv1\n",
            "Pruning layer: layer3.19.conv2\n",
            "Pruning layer: layer3.19.conv3\n",
            "Pruning layer: layer3.20.conv1\n",
            "Pruning layer: layer3.20.conv2\n",
            "Pruning layer: layer3.20.conv3\n",
            "Pruning layer: layer3.21.conv1\n",
            "Pruning layer: layer3.21.conv2\n",
            "Pruning layer: layer3.21.conv3\n",
            "Pruning layer: layer3.22.conv1\n",
            "Pruning layer: layer3.22.conv2\n",
            "Pruning layer: layer3.22.conv3\n",
            "Pruning layer: layer4.0.conv1\n",
            "Pruning layer: layer4.0.conv2\n",
            "Pruning layer: layer4.0.conv3\n",
            "Pruning layer: layer4.1.conv1\n",
            "Pruning layer: layer4.1.conv2\n",
            "Pruning layer: layer4.1.conv3\n",
            "Pruning layer: layer4.2.conv1\n",
            "Pruning layer: layer4.2.conv2\n",
            "Pruning layer: layer4.2.conv3\n",
            "Fine-tuning ResNet101 AFTER pruning iteration...\n",
            "Epoch [1/2] Loss: 0.1047 Time: 261.28s\n",
            "Epoch [2/2] Loss: 0.0603 Time: 261.67s\n",
            "\n",
            "Evaluation Metrics:\n",
            "Accuracy: 76.65%\n",
            "Top-1 Accuracy: 76.65%\n",
            "Top-5 Accuracy: 93.66%\n",
            "Precision (macro): 0.7839\n",
            "Recall (macro):    0.7665\n",
            "F1 Score (macro):  0.7679\n",
            "\n",
            "Iteration 2\n",
            "Pruning layer: conv1\n",
            "Pruning layer: layer1.0.conv1\n",
            "Pruning layer: layer1.0.conv2\n",
            "Pruning layer: layer1.0.conv3\n",
            "Pruning layer: layer1.1.conv1\n",
            "Pruning layer: layer1.1.conv2\n",
            "Pruning layer: layer1.1.conv3\n",
            "Pruning layer: layer1.2.conv1\n",
            "Pruning layer: layer1.2.conv2\n",
            "Pruning layer: layer1.2.conv3\n",
            "Pruning layer: layer2.0.conv1\n",
            "Pruning layer: layer2.0.conv2\n",
            "Pruning layer: layer2.0.conv3\n",
            "Pruning layer: layer2.1.conv1\n",
            "Pruning layer: layer2.1.conv2\n",
            "Pruning layer: layer2.1.conv3\n",
            "Pruning layer: layer2.2.conv1\n",
            "Pruning layer: layer2.2.conv2\n",
            "Pruning layer: layer2.2.conv3\n",
            "Pruning layer: layer2.3.conv1\n",
            "Pruning layer: layer2.3.conv2\n",
            "Pruning layer: layer2.3.conv3\n",
            "Pruning layer: layer3.0.conv1\n",
            "Pruning layer: layer3.0.conv2\n",
            "Pruning layer: layer3.0.conv3\n",
            "Pruning layer: layer3.1.conv1\n",
            "Pruning layer: layer3.1.conv2\n",
            "Pruning layer: layer3.1.conv3\n",
            "Pruning layer: layer3.2.conv1\n",
            "Pruning layer: layer3.2.conv2\n",
            "Pruning layer: layer3.2.conv3\n",
            "Pruning layer: layer3.3.conv1\n",
            "Pruning layer: layer3.3.conv2\n",
            "Pruning layer: layer3.3.conv3\n",
            "Pruning layer: layer3.4.conv1\n",
            "Pruning layer: layer3.4.conv2\n",
            "Pruning layer: layer3.4.conv3\n",
            "Pruning layer: layer3.5.conv1\n",
            "Pruning layer: layer3.5.conv2\n",
            "Pruning layer: layer3.5.conv3\n",
            "Pruning layer: layer3.6.conv1\n",
            "Pruning layer: layer3.6.conv2\n",
            "Pruning layer: layer3.6.conv3\n",
            "Pruning layer: layer3.7.conv1\n",
            "Pruning layer: layer3.7.conv2\n",
            "Pruning layer: layer3.7.conv3\n",
            "Pruning layer: layer3.8.conv1\n",
            "Pruning layer: layer3.8.conv2\n",
            "Pruning layer: layer3.8.conv3\n",
            "Pruning layer: layer3.9.conv1\n",
            "Pruning layer: layer3.9.conv2\n",
            "Pruning layer: layer3.9.conv3\n",
            "Pruning layer: layer3.10.conv1\n",
            "Pruning layer: layer3.10.conv2\n",
            "Pruning layer: layer3.10.conv3\n",
            "Pruning layer: layer3.11.conv1\n",
            "Pruning layer: layer3.11.conv2\n",
            "Pruning layer: layer3.11.conv3\n",
            "Pruning layer: layer3.12.conv1\n",
            "Pruning layer: layer3.12.conv2\n",
            "Pruning layer: layer3.12.conv3\n",
            "Pruning layer: layer3.13.conv1\n",
            "Pruning layer: layer3.13.conv2\n",
            "Pruning layer: layer3.13.conv3\n",
            "Pruning layer: layer3.14.conv1\n",
            "Pruning layer: layer3.14.conv2\n",
            "Pruning layer: layer3.14.conv3\n",
            "Pruning layer: layer3.15.conv1\n",
            "Pruning layer: layer3.15.conv2\n",
            "Pruning layer: layer3.15.conv3\n",
            "Pruning layer: layer3.16.conv1\n",
            "Pruning layer: layer3.16.conv2\n",
            "Pruning layer: layer3.16.conv3\n",
            "Pruning layer: layer3.17.conv1\n",
            "Pruning layer: layer3.17.conv2\n",
            "Pruning layer: layer3.17.conv3\n",
            "Pruning layer: layer3.18.conv1\n",
            "Pruning layer: layer3.18.conv2\n",
            "Pruning layer: layer3.18.conv3\n",
            "Pruning layer: layer3.19.conv1\n",
            "Pruning layer: layer3.19.conv2\n",
            "Pruning layer: layer3.19.conv3\n",
            "Pruning layer: layer3.20.conv1\n",
            "Pruning layer: layer3.20.conv2\n",
            "Pruning layer: layer3.20.conv3\n",
            "Pruning layer: layer3.21.conv1\n",
            "Pruning layer: layer3.21.conv2\n",
            "Pruning layer: layer3.21.conv3\n",
            "Pruning layer: layer3.22.conv1\n",
            "Pruning layer: layer3.22.conv2\n",
            "Pruning layer: layer3.22.conv3\n",
            "Pruning layer: layer4.0.conv1\n",
            "Pruning layer: layer4.0.conv2\n",
            "Pruning layer: layer4.0.conv3\n",
            "Pruning layer: layer4.1.conv1\n",
            "Pruning layer: layer4.1.conv2\n",
            "Pruning layer: layer4.1.conv3\n",
            "Pruning layer: layer4.2.conv1\n",
            "Pruning layer: layer4.2.conv2\n",
            "Pruning layer: layer4.2.conv3\n",
            "Fine-tuning ResNet101 AFTER pruning iteration...\n",
            "Epoch [1/2] Loss: 0.0549 Time: 261.50s\n",
            "Epoch [2/2] Loss: 0.0511 Time: 261.44s\n",
            "\n",
            "Evaluation Metrics:\n",
            "Accuracy: 76.32%\n",
            "Top-1 Accuracy: 76.32%\n",
            "Top-5 Accuracy: 93.29%\n",
            "Precision (macro): 0.7843\n",
            "Recall (macro):    0.7632\n",
            "F1 Score (macro):  0.7641\n",
            "\n",
            "Compression Details AFTER Iterative Pruning:\n",
            "Total Parameters: 42697380\n",
            "Nonzero Parameters: 34683130\n",
            "Compression Ratio: 1.231x\n",
            "Sparsity: 18.770%\n",
            "\n",
            "ResNet101 inference speed AFTER Iterative Pruning:\n",
            "Inference Speed: 0.000182 sec/sample (5494.65 FPS)\n",
            "Inference Speed: 0.000182 sec/sample (5494.65 FPS)\n",
            "\n",
            "All done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### MobileNetV2"
      ],
      "metadata": {
        "id": "SIxnc6NzyI8q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n=== MobileNetV2 Example (CIFAR-100)  ===\")\n",
        "\n",
        "# 1) Define model for CIFAR-100\n",
        "mobilenet_model = MobileNetV2(num_classes=num_classes).to(device)\n",
        "\n",
        "# 2) Load pretrained weights\n",
        "model_path = \"/content/drive/My Drive/Models/CIFAR100/Model@Mobilenetv2_ACC@79.32.pt\"\n",
        "checkpoint = torch.load(model_path, map_location=device)\n",
        "mobilenet_model.load_state_dict(checkpoint)\n",
        "\n",
        "mobilenet_model.eval()\n",
        "\n",
        "# 3) Setup optimizer/loss\n",
        "optimizer_mb = optim.Adam(mobilenet_model.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# 4) Baseline evaluation\n",
        "print(\"MobileNetV2 baseline evaluation (CIFAR-100):\")\n",
        "mb_acc_before, mb_top1_before, mb_top5_before, mb_precision_before, mb_recall_before, mb_f1_before = evaluate_model(mobilenet_model, testloader)\n",
        "\n",
        "print(\"\\nCompression Details Before Pruning:\")\n",
        "mb_compression_before, mb_sparsity_before = count_nonzero_params(mobilenet_model)\n",
        "\n",
        "print(\"\\nInference Speed Before Pruning:\")\n",
        "mb_time_before, mb_fps_before = measure_inference_speed(mobilenet_model, testloader, device)\n",
        "print(f\"Inference Speed: {mb_time_before:.6f} sec/sample ({mb_fps_before:.2f} FPS)\")\n",
        "\n",
        "# 5) Setup for Pruning\n",
        "layer_store_mb = [m for m in mobilenet_model.modules() if isinstance(m, nn.Conv2d)]\n",
        "layers_to_prune_mb = [\n",
        "    name for name, module in mobilenet_model.named_modules()\n",
        "    if isinstance(module, nn.Conv2d) and 'shortcut' not in name and 'layers' not in name\n",
        "]\n",
        "\n",
        "conv_to_bn_map_mb = {}\n",
        "prev_conv = None\n",
        "for name, module in mobilenet_model.named_modules():\n",
        "    if isinstance(module, nn.Conv2d):\n",
        "        prev_conv = name\n",
        "    elif isinstance(module, nn.BatchNorm2d) and prev_conv:\n",
        "        conv_to_bn_map_mb[prev_conv] = name\n",
        "        prev_conv = None\n",
        "\n",
        "# --------------------------------------------------------- #\n",
        "# ONE-SHOT PRUNING                                          #\n",
        "# --------------------------------------------------------- #\n",
        "print(\"\\n--- MobileNetV2 One-Shot Pruning (CIFAR-100) ---\")\n",
        "prune_engine_mb = pruning_engine(\n",
        "    pruning_method=\"L1norm\",\n",
        "    pruning_ratio=0.2,           # 20% pruned\n",
        "    conv_to_bn_map=conv_to_bn_map_mb\n",
        ")\n",
        "\n",
        "for layer_name in layers_to_prune_mb:\n",
        "    print(f\"Pruning layer: {layer_name}\")\n",
        "    current_layer = get_module_by_name(mobilenet_model, layer_name)\n",
        "    prune_engine_mb.set_layer(current_layer, main_layer=True)\n",
        "    masked_layer = prune_engine_mb.remove_conv_filter_kernel(conv_name=layer_name, model=mobilenet_model)\n",
        "    set_module_by_name(mobilenet_model, layer_name, masked_layer)\n",
        "\n",
        "    # Optionally also prune BN\n",
        "    if layer_name in conv_to_bn_map_mb:\n",
        "        bn_name = conv_to_bn_map_mb[layer_name]\n",
        "        bn_layer = get_module_by_name(mobilenet_model, bn_name)\n",
        "        prune_engine_mb.remove_bn_layer(bn_layer, prune_engine_mb.remove_filter_idx_history[\"current_layer\"])\n",
        "\n",
        "# Evaluate after One-Shot\n",
        "print(\"MobileNetV2 evaluation AFTER One-Shot Pruning (CIFAR-100):\")\n",
        "mb_acc_oneshot, mb_top1_oneshot, mb_top5_oneshot, mb_precision_oneshot, mb_recall_oneshot, mb_f1_oneshot = evaluate_model(mobilenet_model, testloader)\n",
        "\n",
        "print(\"\\nCompression Details AFTER One-Shot Pruning:\")\n",
        "mb_compression_oneshot, mb_sparsity_oneshot = count_nonzero_params(mobilenet_model)\n",
        "\n",
        "print(\"\\nInference Speed AFTER One-Shot Pruning:\")\n",
        "mb_time_oneshot, mb_fps_oneshot = measure_inference_speed(mobilenet_model, testloader, device)\n",
        "print(f\"Inference Speed: {mb_time_oneshot:.6f} sec/sample ({mb_fps_oneshot:.2f} FPS)\")\n",
        "\n",
        "# --------------------------------------------------------- #\n",
        "# ITERATIVE PRUNING                                         #\n",
        "# --------------------------------------------------------- #\n",
        "print(\"\\n--- MobileNetV2 Iterative Pruning (CIFAR-100) ---\")\n",
        "num_iter = 2\n",
        "iter_mask_ratio = 0.1\n",
        "\n",
        "for it in range(num_iter):\n",
        "    print(f\"\\nIteration {it + 1}\")\n",
        "\n",
        "    prune_engine_iter_mb = pruning_engine(\n",
        "        pruning_method=\"L1norm\",\n",
        "        pruning_ratio=iter_mask_ratio,\n",
        "        conv_to_bn_map=conv_to_bn_map_mb\n",
        "    )\n",
        "\n",
        "    for layer_name in layers_to_prune_mb:\n",
        "        print(f\"Pruning layer: {layer_name}\")\n",
        "        current_layer = get_module_by_name(mobilenet_model, layer_name)\n",
        "        prune_engine_iter_mb.set_layer(current_layer, main_layer=True)\n",
        "        masked_layer = prune_engine_iter_mb.remove_conv_filter_kernel(conv_name=layer_name, model=mobilenet_model)\n",
        "        set_module_by_name(mobilenet_model, layer_name, masked_layer)\n",
        "\n",
        "        if layer_name in conv_to_bn_map_mb:\n",
        "            bn_name = conv_to_bn_map_mb[layer_name]\n",
        "            bn_layer = get_module_by_name(mobilenet_model, bn_name)\n",
        "            prune_engine_iter_mb.remove_bn_layer(bn_layer, prune_engine_iter_mb.remove_filter_idx_history[\"current_layer\"])\n",
        "\n",
        "    print(\"Fine-tuning MobileNetV2 after pruning iteration...\")\n",
        "    mobilenet_model = train_model(mobilenet_model, trainloader, optimizer_mb, criterion, num_epochs=2)\n",
        "\n",
        "# Final evaluation\n",
        "print(\"MobileNetV2 evaluation after Iterative Pruning:\")\n",
        "mb_acc_iter, mb_top1_iter, mb_top5_iter, mb_precision_iter, mb_recall_iter, mb_f1_iter = evaluate_model(mobilenet_model, testloader)\n",
        "\n",
        "print(\"\\nCompression Details After Iterative Pruning:\")\n",
        "mb_compression_iter, mb_sparsity_iter = count_nonzero_params(mobilenet_model)\n",
        "\n",
        "print(\"\\nInference Speed After Iterative Pruning:\")\n",
        "mb_time_iter, mb_fps_iter = measure_inference_speed(mobilenet_model, testloader, device)\n",
        "print(f\"Inference Speed: {mb_time_iter:.6f} sec/sample ({mb_fps_iter:.2f} FPS)\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ob5IBetryNPV",
        "outputId": "145376cb-e16c-479d-9d16-6de61951cc47"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== MobileNetV2 Example (CIFAR-100)  ===\n",
            "MobileNetV2 baseline evaluation (CIFAR-100):\n",
            "\n",
            "Evaluation Metrics:\n",
            "Accuracy: 78.80%\n",
            "Top-1 Accuracy: 78.80%\n",
            "Top-5 Accuracy: 95.22%\n",
            "Precision (macro): 0.7899\n",
            "Recall (macro):    0.7880\n",
            "F1 Score (macro):  0.7878\n",
            "\n",
            "Compression Details Before Pruning:\n",
            "Total Parameters: 2412212\n",
            "Nonzero Parameters: 2412212\n",
            "Compression Ratio: 1.000x\n",
            "Sparsity: 0.000%\n",
            "\n",
            "Inference Speed Before Pruning:\n",
            "Inference Speed: 0.000201 sec/sample (4965.83 FPS)\n",
            "Inference Speed: 0.000201 sec/sample (4965.83 FPS)\n",
            "\n",
            "--- MobileNetV2 One-Shot Pruning (CIFAR-100) ---\n",
            "Pruning layer: conv1\n",
            "Pruning layer: conv2\n",
            "MobileNetV2 evaluation AFTER One-Shot Pruning (CIFAR-100):\n",
            "\n",
            "Evaluation Metrics:\n",
            "Accuracy: 78.29%\n",
            "Top-1 Accuracy: 78.29%\n",
            "Top-5 Accuracy: 94.92%\n",
            "Precision (macro): 0.7888\n",
            "Recall (macro):    0.7829\n",
            "F1 Score (macro):  0.7832\n",
            "\n",
            "Compression Details AFTER One-Shot Pruning:\n",
            "Total Parameters: 2412212\n",
            "Nonzero Parameters: 2329577\n",
            "Compression Ratio: 1.035x\n",
            "Sparsity: 3.426%\n",
            "\n",
            "Inference Speed AFTER One-Shot Pruning:\n",
            "Inference Speed: 0.000209 sec/sample (4776.15 FPS)\n",
            "Inference Speed: 0.000209 sec/sample (4776.15 FPS)\n",
            "\n",
            "--- MobileNetV2 Iterative Pruning (CIFAR-100) ---\n",
            "\n",
            "Iteration 1\n",
            "Pruning layer: conv1\n",
            "Pruning layer: conv2\n",
            "Fine-tuning MobileNetV2 after pruning iteration...\n",
            "Epoch [1/2] Loss: 1.1390 Time: 48.49s\n",
            "Epoch [2/2] Loss: 0.9669 Time: 48.69s\n",
            "\n",
            "Iteration 2\n",
            "Pruning layer: conv1\n",
            "Pruning layer: conv2\n",
            "Fine-tuning MobileNetV2 after pruning iteration...\n",
            "Epoch [1/2] Loss: 0.8563 Time: 48.40s\n",
            "Epoch [2/2] Loss: 0.7978 Time: 48.84s\n",
            "MobileNetV2 evaluation after Iterative Pruning:\n",
            "\n",
            "Evaluation Metrics:\n",
            "Accuracy: 67.36%\n",
            "Top-1 Accuracy: 67.36%\n",
            "Top-5 Accuracy: 90.89%\n",
            "Precision (macro): 0.6950\n",
            "Recall (macro):    0.6736\n",
            "F1 Score (macro):  0.6728\n",
            "\n",
            "Compression Details After Iterative Pruning:\n",
            "Total Parameters: 2412212\n",
            "Nonzero Parameters: 2329577\n",
            "Compression Ratio: 1.035x\n",
            "Sparsity: 3.426%\n",
            "\n",
            "Inference Speed After Iterative Pruning:\n",
            "Inference Speed: 0.000197 sec/sample (5065.99 FPS)\n",
            "Inference Speed: 0.000197 sec/sample (5065.99 FPS)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###VGG16"
      ],
      "metadata": {
        "id": "jxXkJ5JHyQG1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n=== VGG16 Example (CIFAR-100) ===\")\n",
        "\n",
        "# 1) Define model\n",
        "vgg_model = VGG(num_classes=num_classes, vgg_name=\"VGG16\").to(device)\n",
        "\n",
        "# 2) Load pretrained weights\n",
        "model_path = \"/content/drive/My Drive/Models/CIFAR100/Model@VGG16_ACC@76.41.pt\"\n",
        "checkpoint = torch.load(model_path, map_location=device)\n",
        "vgg_model.load_state_dict(checkpoint)\n",
        "\n",
        "# 3) Set to eval mode\n",
        "vgg_model.eval()\n",
        "\n",
        "# 4) Optimizer & Loss\n",
        "optimizer_vgg = optim.Adam(vgg_model.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# === Baseline Evaluation === #\n",
        "print(\"VGG16 baseline evaluation:\")\n",
        "vgg_acc_before, vgg_top1_acc_before, vgg_top5_acc_before, vgg_precision_before, vgg_recall_before, vgg_f1score_before = evaluate_model(vgg_model, testloader)\n",
        "\n",
        "# Compression\n",
        "print(f'\\nCompression Details Before Pruning:')\n",
        "vgg_compression_ratio_before, vgg_sparsity_before = count_nonzero_params(vgg_model)\n",
        "\n",
        "# Inference Speed\n",
        "print(f\"\\nVGG16 inference speed BEFORE pruning:\")\n",
        "vgg_avg_time_per_sample_before, vgg_avg_fps_before = measure_inference_speed(vgg_model, testloader, device)\n",
        "print(f\"Inference Speed: {vgg_avg_time_per_sample_before:.6f} sec/sample ({vgg_avg_fps_before:.2f} FPS)\")\n",
        "\n",
        "# Prepare Layers for Pruning\n",
        "layer_store_vgg = [m for m in vgg_model.modules() if isinstance(m, nn.Conv2d)]\n",
        "layers_to_prune_vgg = [name for name, module in vgg_model.named_modules() if isinstance(module, nn.Conv2d)]\n",
        "\n",
        "conv_to_bn_map_vgg = {}\n",
        "prev_conv = None\n",
        "for name, module in vgg_model.named_modules():\n",
        "    if isinstance(module, nn.Conv2d):\n",
        "        prev_conv = name\n",
        "    elif isinstance(module, nn.BatchNorm2d) and prev_conv:\n",
        "        conv_to_bn_map_vgg[prev_conv] = name\n",
        "        prev_conv = None\n",
        "\n",
        "# --------------------------------------------------------- #\n",
        "# ONE-SHOT PRUNING                                          #\n",
        "# --------------------------------------------------------- #\n",
        "print(\"\\n--- VGG16 One-Shot Pruning ---\")\n",
        "prune_engine_vgg = pruning_engine(\n",
        "    pruning_method=\"L1norm\",\n",
        "    pruning_ratio=0.2,   # 20% pruned\n",
        "    conv_to_bn_map=conv_to_bn_map_vgg\n",
        ")\n",
        "\n",
        "for layer_name in layers_to_prune_vgg:\n",
        "    print(f\"Pruning VGG16 layer: {layer_name}\")\n",
        "    orig_layer = get_module_by_name(vgg_model, layer_name)\n",
        "    prune_engine_vgg.set_layer(orig_layer, main_layer=True)\n",
        "    masked_layer = prune_engine_vgg.remove_conv_filter_kernel(conv_name=layer_name, model=vgg_model)\n",
        "    set_module_by_name(vgg_model, layer_name, masked_layer)\n",
        "\n",
        "# === Eval After One-Shot ===\n",
        "print(\"VGG16 evaluation AFTER One-Shot Pruning:\")\n",
        "vgg_acc_oneshot, vgg_top1_acc_oneshot, vgg_top5_acc_oneshot, vgg_precision_oneshot, vgg_recall_oneshot, vgg_f1score_oneshot = evaluate_model(vgg_model, testloader)\n",
        "\n",
        "print(f'\\nCompression Details AFTER One-Shot Pruning:')\n",
        "vgg_compression_ratio_oneshot, vgg_sparsity_oneshot = count_nonzero_params(vgg_model)\n",
        "\n",
        "print(f\"\\nVGG16 inference speed AFTER One-Shot pruning:\")\n",
        "vgg_avg_time_per_sample_oneshot, vgg_avg_fps_oneshot = measure_inference_speed(vgg_model, testloader, device)\n",
        "print(f\"Inference Speed: {vgg_avg_time_per_sample_oneshot:.6f} sec/sample ({vgg_avg_fps_oneshot:.2f} FPS)\")\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# ITERATIVE PRUNING\n",
        "# ---------------------------------------------------------\n",
        "print(\"\\n--- VGG16 Iterative Pruning ---\")\n",
        "num_iter = 2\n",
        "iter_mask_ratio = 0.1\n",
        "\n",
        "for it in range(num_iter):\n",
        "    print(f\"\\nIteration {it+1} for VGG16\")\n",
        "\n",
        "    prune_engine_iter_vgg = pruning_engine(\n",
        "        pruning_method=\"L1norm\",\n",
        "        pruning_ratio=iter_mask_ratio,\n",
        "        conv_to_bn_map=conv_to_bn_map_vgg\n",
        "    )\n",
        "\n",
        "    for layer_name in layers_to_prune_vgg:\n",
        "        print(f\"Pruning VGG16 layer: {layer_name}\")\n",
        "        current_layer = get_module_by_name(vgg_model, layer_name)\n",
        "        prune_engine_iter_vgg.set_layer(current_layer, main_layer=True)\n",
        "        masked_layer = prune_engine_iter_vgg.remove_conv_filter_kernel(conv_name=layer_name, model=vgg_model)\n",
        "        set_module_by_name(vgg_model, layer_name, masked_layer)\n",
        "\n",
        "    print(\"Fine-tuning VGG16 after iteration...\")\n",
        "    vgg_model = train_model(vgg_model, trainloader, optimizer_vgg, criterion, num_epochs=2)\n",
        "\n",
        "# === Final Eval After Iterative Pruning ===\n",
        "print(\"VGG16 evaluation AFTER Iterative Pruning:\")\n",
        "vgg_acc_iter, vgg_top1_acc_iter, vgg_top5_acc_iter, vgg_precision_iter, vgg_recall_iter, vgg_f1score_iter = evaluate_model(vgg_model, testloader)\n",
        "\n",
        "print(f'\\nCompression Details AFTER Iterative Pruning:')\n",
        "vgg_compression_ratio_iter, vgg_sparsity_iter = count_nonzero_params(vgg_model)\n",
        "\n",
        "print(f\"\\nVGG16 inference speed AFTER Iterative pruning:\")\n",
        "vgg_avg_time_per_sample_iter, vgg_avg_fps_iter = measure_inference_speed(vgg_model, testloader, device)\n",
        "print(f\"Inference Speed: {vgg_avg_time_per_sample_iter:.6f} sec/sample ({vgg_avg_fps_iter:.2f} FPS)\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AzIrIFi6yTJi",
        "outputId": "61241cec-9c26-4a76-c390-aedbf1a14ed9"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== VGG16 Example (CIFAR-100) ===\n",
            "VGG16 baseline evaluation:\n",
            "\n",
            "Evaluation Metrics:\n",
            "Accuracy: 76.51%\n",
            "Top-1 Accuracy: 76.51%\n",
            "Top-5 Accuracy: 93.48%\n",
            "Precision (macro): 0.7680\n",
            "Recall (macro):    0.7651\n",
            "F1 Score (macro):  0.7653\n",
            "\n",
            "Compression Details Before Pruning:\n",
            "Total Parameters: 34015396\n",
            "Nonzero Parameters: 34015396\n",
            "Compression Ratio: 1.000x\n",
            "Sparsity: 0.000%\n",
            "\n",
            "VGG16 inference speed BEFORE pruning:\n",
            "Inference Speed: 0.000080 sec/sample (12458.06 FPS)\n",
            "Inference Speed: 0.000080 sec/sample (12458.06 FPS)\n",
            "\n",
            "--- VGG16 One-Shot Pruning ---\n",
            "Pruning VGG16 layer: features.0\n",
            "Pruning VGG16 layer: features.3\n",
            "Pruning VGG16 layer: features.7\n",
            "Pruning VGG16 layer: features.10\n",
            "Pruning VGG16 layer: features.14\n",
            "Pruning VGG16 layer: features.17\n",
            "Pruning VGG16 layer: features.20\n",
            "Pruning VGG16 layer: features.24\n",
            "Pruning VGG16 layer: features.27\n",
            "Pruning VGG16 layer: features.30\n",
            "Pruning VGG16 layer: features.34\n",
            "Pruning VGG16 layer: features.37\n",
            "Pruning VGG16 layer: features.40\n",
            "VGG16 evaluation AFTER One-Shot Pruning:\n",
            "\n",
            "Evaluation Metrics:\n",
            "Accuracy: 21.56%\n",
            "Top-1 Accuracy: 21.56%\n",
            "Top-5 Accuracy: 43.17%\n",
            "Precision (macro): 0.5279\n",
            "Recall (macro):    0.2156\n",
            "F1 Score (macro):  0.2122\n",
            "\n",
            "Compression Details AFTER One-Shot Pruning:\n",
            "Total Parameters: 34015396\n",
            "Nonzero Parameters: 31050121\n",
            "Compression Ratio: 1.095x\n",
            "Sparsity: 8.717%\n",
            "\n",
            "VGG16 inference speed AFTER One-Shot pruning:\n",
            "Inference Speed: 0.000063 sec/sample (15887.15 FPS)\n",
            "Inference Speed: 0.000063 sec/sample (15887.15 FPS)\n",
            "\n",
            "--- VGG16 Iterative Pruning ---\n",
            "\n",
            "Iteration 1 for VGG16\n",
            "Pruning VGG16 layer: features.0\n",
            "Pruning VGG16 layer: features.3\n",
            "Pruning VGG16 layer: features.7\n",
            "Pruning VGG16 layer: features.10\n",
            "Pruning VGG16 layer: features.14\n",
            "Pruning VGG16 layer: features.17\n",
            "Pruning VGG16 layer: features.20\n",
            "Pruning VGG16 layer: features.24\n",
            "Pruning VGG16 layer: features.27\n",
            "Pruning VGG16 layer: features.30\n",
            "Pruning VGG16 layer: features.34\n",
            "Pruning VGG16 layer: features.37\n",
            "Pruning VGG16 layer: features.40\n",
            "Fine-tuning VGG16 after iteration...\n",
            "Epoch [1/2] Loss: 0.6606 Time: 27.71s\n",
            "Epoch [2/2] Loss: 0.5474 Time: 27.71s\n",
            "\n",
            "Iteration 2 for VGG16\n",
            "Pruning VGG16 layer: features.0\n",
            "Pruning VGG16 layer: features.3\n",
            "Pruning VGG16 layer: features.7\n",
            "Pruning VGG16 layer: features.10\n",
            "Pruning VGG16 layer: features.14\n",
            "Pruning VGG16 layer: features.17\n",
            "Pruning VGG16 layer: features.20\n",
            "Pruning VGG16 layer: features.24\n",
            "Pruning VGG16 layer: features.27\n",
            "Pruning VGG16 layer: features.30\n",
            "Pruning VGG16 layer: features.34\n",
            "Pruning VGG16 layer: features.37\n",
            "Pruning VGG16 layer: features.40\n",
            "Fine-tuning VGG16 after iteration...\n",
            "Epoch [1/2] Loss: 0.5159 Time: 27.75s\n",
            "Epoch [2/2] Loss: 0.4998 Time: 27.52s\n",
            "VGG16 evaluation AFTER Iterative Pruning:\n",
            "\n",
            "Evaluation Metrics:\n",
            "Accuracy: 66.91%\n",
            "Top-1 Accuracy: 66.91%\n",
            "Top-5 Accuracy: 88.19%\n",
            "Precision (macro): 0.6820\n",
            "Recall (macro):    0.6691\n",
            "F1 Score (macro):  0.6692\n",
            "\n",
            "Compression Details AFTER Iterative Pruning:\n",
            "Total Parameters: 34015396\n",
            "Nonzero Parameters: 31050121\n",
            "Compression Ratio: 1.095x\n",
            "Sparsity: 8.717%\n",
            "\n",
            "VGG16 inference speed AFTER Iterative pruning:\n",
            "Inference Speed: 0.000089 sec/sample (11298.12 FPS)\n",
            "Inference Speed: 0.000089 sec/sample (11298.12 FPS)\n"
          ]
        }
      ]
    }
  ]
}